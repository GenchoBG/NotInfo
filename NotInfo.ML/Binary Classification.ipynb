{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Embedding, LSTM, Bidirectional, GlobalMaxPool1D, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.abspath('.')\n",
    "dataframe = pd.read_csv(os.path.join(path, 'data', 'data.txt'), delimiter='\\t', names=['article', 'id', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Et tu, Rhody?  A recent editorial in the Provi...</td>\n",
       "      <td>727600136</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A recent post in The Farmington Mirror — our t...</td>\n",
       "      <td>731714618</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>President Donald Trump, as he often does while...</td>\n",
       "      <td>731714635</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>February is Black History Month, and nothing l...</td>\n",
       "      <td>728627182</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The snow was so heavy, whipped up by gusting w...</td>\n",
       "      <td>728627443</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Four months after the Sandy Hook School shooti...</td>\n",
       "      <td>732126660</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The first major newspaper article about Donald...</td>\n",
       "      <td>728144791</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>For three years, starting in 2008, New York ar...</td>\n",
       "      <td>728605281</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>President Donald Trump's tumultuous administra...</td>\n",
       "      <td>731383701</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>With Hartford on edge about the future of Aetn...</td>\n",
       "      <td>734075146</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>An employee at a Hibachi Express in Florida ha...</td>\n",
       "      <td>730014413</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>With the toll of the carnage from the country’...</td>\n",
       "      <td>731000618</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The State Department's point-man on North Kore...</td>\n",
       "      <td>734267317</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Trump Organization announced Monday that i...</td>\n",
       "      <td>734268392</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Aer Lingus’ service from Bradley International...</td>\n",
       "      <td>732544725</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>For its show “Constellations,” which ends its ...</td>\n",
       "      <td>732544983</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Corporation for Public Broadcasting (CPB) ...</td>\n",
       "      <td>733933352</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>All five members of New Britain’s state legisl...</td>\n",
       "      <td>729599944</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The leader and second in command of a credit-c...</td>\n",
       "      <td>729092528</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>After eight years as the state’s relentless ch...</td>\n",
       "      <td>729092995</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Aetna Inc. is being sued in yet another legal ...</td>\n",
       "      <td>729093525</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Erin Stewart will be out of sight, but not out...</td>\n",
       "      <td>732605196</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dozens of Meriden residents and city officials...</td>\n",
       "      <td>732605617</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Two classic American novels will no longer be ...</td>\n",
       "      <td>729829440</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>We asked our friends on Facebook and Twitter t...</td>\n",
       "      <td>728544641</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MassMutual announced Thursday it is closing it...</td>\n",
       "      <td>729313115</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Amid federal inaction on gun control, the Demo...</td>\n",
       "      <td>733130852</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Linda Greenhouse, the award-winning New York T...</td>\n",
       "      <td>733131088</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Stephen Colbert would like to change the votin...</td>\n",
       "      <td>732789288</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>In the wake of the shooting death of 15-year-o...</td>\n",
       "      <td>729194501</td>\n",
       "      <td>non-propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35956</th>\n",
       "      <td>“The best way to teach your kids about taxes i...</td>\n",
       "      <td>694381164</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35957</th>\n",
       "      <td>[This article is excerpted from volume 2, chap...</td>\n",
       "      <td>694381211</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35958</th>\n",
       "      <td>I remember the moment I got the HPV vaccine. I...</td>\n",
       "      <td>694381405</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35959</th>\n",
       "      <td>“These are, after all, the same entities who i...</td>\n",
       "      <td>694382687</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35960</th>\n",
       "      <td>Madagascar isn’t getting this epidemic of the ...</td>\n",
       "      <td>701521336</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35961</th>\n",
       "      <td>WikiLeaks founder Julian Assange has accused H...</td>\n",
       "      <td>698536805</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35962</th>\n",
       "      <td>Every ideologically driven citizen has one law...</td>\n",
       "      <td>698537030</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35963</th>\n",
       "      <td>On 31 August 1888 Mary Ann Nichols, the first ...</td>\n",
       "      <td>783694526</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35964</th>\n",
       "      <td>By nature all men are equal in liberty but not...</td>\n",
       "      <td>783694592</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35965</th>\n",
       "      <td>The following is the foreword that I have writ...</td>\n",
       "      <td>783694820</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35966</th>\n",
       "      <td>https://www.lewrockwell.com/lrc-blog/american-...</td>\n",
       "      <td>783929870</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35967</th>\n",
       "      <td>Joe Lauria, editor-in-chief of Consortium News...</td>\n",
       "      <td>784033478</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35968</th>\n",
       "      <td>Just because he’s dead doesn’t mean John McCai...</td>\n",
       "      <td>784266021</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35969</th>\n",
       "      <td>A recently posted commentary by Ben Shapiro on...</td>\n",
       "      <td>784266637</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35970</th>\n",
       "      <td>Moscow has seen attempts to meddle in the Russ...</td>\n",
       "      <td>784555004</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35971</th>\n",
       "      <td>Seven years after the beginning of the war aga...</td>\n",
       "      <td>784555056</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35972</th>\n",
       "      <td>In April 2005, a Republican-led Department of ...</td>\n",
       "      <td>784555422</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35973</th>\n",
       "      <td>Many of us in the South have maintained our fa...</td>\n",
       "      <td>784556485</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35974</th>\n",
       "      <td>In an interview with Consortium News Editor-in...</td>\n",
       "      <td>784855236</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35975</th>\n",
       "      <td>Shop all books by Judge Napolitano  Last week,...</td>\n",
       "      <td>784855886</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35976</th>\n",
       "      <td>https://www.lewrockwell.com/lrc-blog/why-bob-w...</td>\n",
       "      <td>785266460</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35977</th>\n",
       "      <td>Fellow Americans,  Please know: I am black; I ...</td>\n",
       "      <td>785149287</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35978</th>\n",
       "      <td>The past is not dead; it is people who are sle...</td>\n",
       "      <td>785429194</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35979</th>\n",
       "      <td>The New York Times continues to outdo itself i...</td>\n",
       "      <td>785429583</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35980</th>\n",
       "      <td>“It’s very depressing. You want to read a depr...</td>\n",
       "      <td>785430430</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35981</th>\n",
       "      <td>From The Telegraph:  Towns in Brazil have beco...</td>\n",
       "      <td>785781276</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35982</th>\n",
       "      <td>The second episode of Consortium News on Flash...</td>\n",
       "      <td>785781322</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35983</th>\n",
       "      <td>It is beginning.  Actually, it’s been happenin...</td>\n",
       "      <td>785781455</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35984</th>\n",
       "      <td>Justin’s note: As regular Dispatch readers kno...</td>\n",
       "      <td>785781711</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35985</th>\n",
       "      <td>“No man can serve two masters” (Matthew 6:24)....</td>\n",
       "      <td>786060460</td>\n",
       "      <td>propaganda</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35986 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 article         id  \\\n",
       "0      Et tu, Rhody?  A recent editorial in the Provi...  727600136   \n",
       "1      A recent post in The Farmington Mirror — our t...  731714618   \n",
       "2      President Donald Trump, as he often does while...  731714635   \n",
       "3      February is Black History Month, and nothing l...  728627182   \n",
       "4      The snow was so heavy, whipped up by gusting w...  728627443   \n",
       "5      Four months after the Sandy Hook School shooti...  732126660   \n",
       "6      The first major newspaper article about Donald...  728144791   \n",
       "7      For three years, starting in 2008, New York ar...  728605281   \n",
       "8      President Donald Trump's tumultuous administra...  731383701   \n",
       "9      With Hartford on edge about the future of Aetn...  734075146   \n",
       "10     An employee at a Hibachi Express in Florida ha...  730014413   \n",
       "11     With the toll of the carnage from the country’...  731000618   \n",
       "12     The State Department's point-man on North Kore...  734267317   \n",
       "13     The Trump Organization announced Monday that i...  734268392   \n",
       "14     Aer Lingus’ service from Bradley International...  732544725   \n",
       "15     For its show “Constellations,” which ends its ...  732544983   \n",
       "16     The Corporation for Public Broadcasting (CPB) ...  733933352   \n",
       "17     All five members of New Britain’s state legisl...  729599944   \n",
       "18     The leader and second in command of a credit-c...  729092528   \n",
       "19     After eight years as the state’s relentless ch...  729092995   \n",
       "20     Aetna Inc. is being sued in yet another legal ...  729093525   \n",
       "21     Erin Stewart will be out of sight, but not out...  732605196   \n",
       "22     Dozens of Meriden residents and city officials...  732605617   \n",
       "23     Two classic American novels will no longer be ...  729829440   \n",
       "24     We asked our friends on Facebook and Twitter t...  728544641   \n",
       "25     MassMutual announced Thursday it is closing it...  729313115   \n",
       "26     Amid federal inaction on gun control, the Demo...  733130852   \n",
       "27     Linda Greenhouse, the award-winning New York T...  733131088   \n",
       "28     Stephen Colbert would like to change the votin...  732789288   \n",
       "29     In the wake of the shooting death of 15-year-o...  729194501   \n",
       "...                                                  ...        ...   \n",
       "35956  “The best way to teach your kids about taxes i...  694381164   \n",
       "35957  [This article is excerpted from volume 2, chap...  694381211   \n",
       "35958  I remember the moment I got the HPV vaccine. I...  694381405   \n",
       "35959  “These are, after all, the same entities who i...  694382687   \n",
       "35960  Madagascar isn’t getting this epidemic of the ...  701521336   \n",
       "35961  WikiLeaks founder Julian Assange has accused H...  698536805   \n",
       "35962  Every ideologically driven citizen has one law...  698537030   \n",
       "35963  On 31 August 1888 Mary Ann Nichols, the first ...  783694526   \n",
       "35964  By nature all men are equal in liberty but not...  783694592   \n",
       "35965  The following is the foreword that I have writ...  783694820   \n",
       "35966  https://www.lewrockwell.com/lrc-blog/american-...  783929870   \n",
       "35967  Joe Lauria, editor-in-chief of Consortium News...  784033478   \n",
       "35968  Just because he’s dead doesn’t mean John McCai...  784266021   \n",
       "35969  A recently posted commentary by Ben Shapiro on...  784266637   \n",
       "35970  Moscow has seen attempts to meddle in the Russ...  784555004   \n",
       "35971  Seven years after the beginning of the war aga...  784555056   \n",
       "35972  In April 2005, a Republican-led Department of ...  784555422   \n",
       "35973  Many of us in the South have maintained our fa...  784556485   \n",
       "35974  In an interview with Consortium News Editor-in...  784855236   \n",
       "35975  Shop all books by Judge Napolitano  Last week,...  784855886   \n",
       "35976  https://www.lewrockwell.com/lrc-blog/why-bob-w...  785266460   \n",
       "35977  Fellow Americans,  Please know: I am black; I ...  785149287   \n",
       "35978  The past is not dead; it is people who are sle...  785429194   \n",
       "35979  The New York Times continues to outdo itself i...  785429583   \n",
       "35980  “It’s very depressing. You want to read a depr...  785430430   \n",
       "35981  From The Telegraph:  Towns in Brazil have beco...  785781276   \n",
       "35982  The second episode of Consortium News on Flash...  785781322   \n",
       "35983  It is beginning.  Actually, it’s been happenin...  785781455   \n",
       "35984  Justin’s note: As regular Dispatch readers kno...  785781711   \n",
       "35985  “No man can serve two masters” (Matthew 6:24)....  786060460   \n",
       "\n",
       "                label  \n",
       "0      non-propaganda  \n",
       "1      non-propaganda  \n",
       "2      non-propaganda  \n",
       "3      non-propaganda  \n",
       "4      non-propaganda  \n",
       "5      non-propaganda  \n",
       "6      non-propaganda  \n",
       "7      non-propaganda  \n",
       "8      non-propaganda  \n",
       "9      non-propaganda  \n",
       "10     non-propaganda  \n",
       "11     non-propaganda  \n",
       "12     non-propaganda  \n",
       "13     non-propaganda  \n",
       "14     non-propaganda  \n",
       "15     non-propaganda  \n",
       "16     non-propaganda  \n",
       "17     non-propaganda  \n",
       "18     non-propaganda  \n",
       "19     non-propaganda  \n",
       "20     non-propaganda  \n",
       "21     non-propaganda  \n",
       "22     non-propaganda  \n",
       "23     non-propaganda  \n",
       "24     non-propaganda  \n",
       "25     non-propaganda  \n",
       "26     non-propaganda  \n",
       "27     non-propaganda  \n",
       "28     non-propaganda  \n",
       "29     non-propaganda  \n",
       "...               ...  \n",
       "35956      propaganda  \n",
       "35957      propaganda  \n",
       "35958      propaganda  \n",
       "35959      propaganda  \n",
       "35960      propaganda  \n",
       "35961      propaganda  \n",
       "35962      propaganda  \n",
       "35963      propaganda  \n",
       "35964      propaganda  \n",
       "35965      propaganda  \n",
       "35966      propaganda  \n",
       "35967      propaganda  \n",
       "35968      propaganda  \n",
       "35969      propaganda  \n",
       "35970      propaganda  \n",
       "35971      propaganda  \n",
       "35972      propaganda  \n",
       "35973      propaganda  \n",
       "35974      propaganda  \n",
       "35975      propaganda  \n",
       "35976      propaganda  \n",
       "35977      propaganda  \n",
       "35978      propaganda  \n",
       "35979      propaganda  \n",
       "35980      propaganda  \n",
       "35981      propaganda  \n",
       "35982      propaganda  \n",
       "35983      propaganda  \n",
       "35984      propaganda  \n",
       "35985      propaganda  \n",
       "\n",
       "[35986 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Et tu, Rhody?  A recent editorial in the Providence Journal cataloged everything it could find wrong with Connecticut and ended with this suggestion: “Gov. Gina Raimondo should see if at least some of those jobs could come to Rhode Island. It is certainly less risky than the Nutmeg State.”  We beg your pardon.  The state with world-famous pension problems and persistent economic issues of its own is “less risky”?  The Journal itself reported just a few weeks ago on Rhode Island’s own significant economic problems, which in many ways reflect Connecticut’s.  Rhode Island enjoys a legacy of corruption that not even Connecticut can match. The ProJo won a Pulitzer Prize in 1994 for uncovering widespread corruption within its own court system.  What, exactly, is to be gained from moving to Rhode Island?  Like Connecticut, Rhode Island has an income tax and an estate tax with comparable rates. (Forbes magazine listed it as one of the states “Where Not To Die.” Connecticut made the list, too.)  Connecticut and Rhode Island’s interdependence has been limited, with the exception of the interstate economy created by Electric Boat in Groton. There have been no border wars and very little bloodshed. A few jokes about Rhode Island’s size, maybe, but if we’re being honest, Connecticut doesn’t really have a lot going on in that department either.  A little interstate competition is fine, but if Connecticut suffers, so does Rhode Island — and all of New England, for that matter.  Connecticut is losing residents at a troubling rate, but Rhode Island has an outmigration problem of its own. From 2015 to 2016, the Ocean State experienced a net loss of about 2,000 tax filers, who took with them more than $182 million in adjusted gross income. The top destination states for people who fled Rhode Island were Massachusetts, Florida and — wait for it — Connecticut.  Connecticut residents moved to Rhode Island as well, of course. But Connecticut’s population is 3½ times as big as Rhode Island’s. So the 1,175 tax filers who left Rhode Island for Connecticut represent a far larger portion of the Ocean State than the 1,220 who moved from Connecticut to Rhode Island. If any state should be concerned about losing residents to its neighbor, it’s Rhode Island.  But we don’t want to poach Rhode Islanders. We’d rather celebrate Electric Boat’s growth and the burgeoning workforce that supports both states. We’d rather cheer CVS for buying Aetna and keeping it in Hartford than try to woo CVS from Woonsocket.  A booming Connecticut, especially in the insurance and defense industries, only helps Rhode Island.  As Electric Boat — headquartered in Connecticut, might we emphasize — grows over the next decade, the effect on Little Rhody will be profound, as the ProJo’s editorial board pointed out. A thriving border economy helps both states as supplier chains develop and as feeder businesses bloom.  But for the same reasons that the stain of a Hartford bankruptcy would spread to the suburbs, if Connecticut becomes an economic wasteland, the effects would be felt across New England.  If Rhode Island and Connecticut want to find a way out of the muck, far better for them to work together.  Yes, Connecticut can learn from Rhode Island. Connecticut’s pension problems are similar to those that threatened to swamp Rhode Island, but there are key differences, especially in that Connecticut’s pensions are contractual, where in Rhode Island, they were set by state statute.  Rhode Island made some tough choices and anticipated a legal battle to solve its problems. Connecticut leaders might have to find the stomach for the same type of strategy.  Connecticut and Rhode Island have a lot in common, including language. We both drive around the rotary to get a grinder at Cumbie’s, for example. And we are glad that Rhode Island has made progress on its pension issues.  But that’s no reason to try to poach a few residents. A regional approach would be much wiser.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['article'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "non-propaganda    31965\n",
       "propaganda         4021\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_mapping = {'propaganda': 1, 'non-propaganda': 0}\n",
    "dataframe['target'] = dataframe['label'].map(value_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextPreprocessor():\n",
    "    def __init__(self):\n",
    "        # clean_text helpers\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = stopwords.words(\"english\")\n",
    "        self.vectorizer = CountVectorizer()\n",
    "        self.cvecTtokenizer = self.vectorizer.build_tokenizer()\n",
    "        # prepare_for_model helpers\n",
    "        self.max_features = 6000 # I pulled this out of my ass\n",
    "        self.max_sequence_length = 348 # I also pulled this out of my ass\n",
    "        self.sequence_tokenizer = Tokenizer(num_words = self.max_features)\n",
    "        \n",
    "    def clean_text(self, text):\n",
    "        # Remove special chars and punctuation\n",
    "        text = \" \".join(self.cvecTtokenizer(text))\n",
    "        # lowcase\n",
    "        text = text.lower()\n",
    "        # Lematize\n",
    "        text = [self.lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
    "        text = [self.lemmatizer.lemmatize(token, \"v\") for token in text]\n",
    "        # Remove stopwords\n",
    "        text = [word for word in text if not word in self.stop_words]\n",
    "\n",
    "        text = \" \".join(text)\n",
    "        return text\n",
    "    \n",
    "    def prepare_for_model(self, text):\n",
    "        return pad_sequences(self.sequence_tokenizer.texts_to_sequences(text), maxlen = self.max_sequence_length)\n",
    "    \n",
    "    def fit_sequence_tokenizer(self, texts_to_fit):\n",
    "        self.sequence_tokenizer.fit_on_texts(texts_to_fit)\n",
    "        \n",
    "    def save_sequence_tokenizer(self, path):\n",
    "        with open(path, 'wb') as handle:\n",
    "            pickle.dump(self.sequence_tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "            \n",
    "    def load_sequence_tokenizer(self, path):\n",
    "        with open(path, 'rb') as handle:\n",
    "            self.sequence_tokenizer = pickle.load(handle)\n",
    "        \n",
    "        \n",
    "textPreprocessor = TextPreprocessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['article_prepared'] = dataframe['article'].apply(textPreprocessor.clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35986.000000\n",
       "mean       346.711916\n",
       "std        289.532668\n",
       "min          4.000000\n",
       "25%        171.000000\n",
       "50%        280.000000\n",
       "75%        449.000000\n",
       "max      12122.000000\n",
       "Name: article_prepared, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember when I said I pulled numbers out of my ass? I actually guestimated them based on this...\n",
    "dataframe['article_prepared'].apply(lambda x: len(x.split(\" \"))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "textPreprocessor.fit_sequence_tokenizer(dataframe['article_prepared'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0, 1493]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textPreprocessor.prepare_for_model(dataframe['article_prepared'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_tokenizer_path = './model/sequence_tokenizer.pickle'\n",
    "textPreprocessor.save_sequence_tokenizer(save_tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "textPreprocessor.load_sequence_tokenizer(save_tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0,    0],\n",
       "       [   0,    0,    0, ...,    0,    0, 1493]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textPreprocessor.prepare_for_model(dataframe['article_prepared'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: Clean up that mess above..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PropagandaDetector():\n",
    "    def __init__(self, textPreprocessor, model_path = None):\n",
    "        self.textPreprocessor = textPreprocessor\n",
    "        \n",
    "        if model_path:\n",
    "            self.model = load_model(model_path)\n",
    "        else:\n",
    "            self.embed_size = 200 # Remember where I get my magic numbers from?\n",
    "            self.model = Sequential()\n",
    "            self.model.add(Embedding(textPreprocessor.max_features, self.embed_size))\n",
    "            self.model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
    "            self.model.add(GlobalMaxPool1D())\n",
    "            self.model.add(Dense(20, activation=\"relu\"))\n",
    "            self.model.add(Dropout(0.1))\n",
    "            self.model.add(Dense(1, activation=\"sigmoid\"))\n",
    "            self.model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "            self.model.summary()\n",
    "        \n",
    "    def train(self, features, labels):        \n",
    "        self.model.fit(features, labels, batch_size=128, epochs=2)\n",
    "        \n",
    "    def detect_propaganda(self, text):\n",
    "        cleaned = self.textPreprocessor.clean_text(text)\n",
    "        prepared = self.textPreprocessor.prepare_for_model([cleaned])\n",
    "        confidence = self.model.predict(prepared, verbose=1)[0][0]\n",
    "        return (confidence >= 0.5, confidence)\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        self.model.save(path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1003 13:06:45.119067 20160 deprecation.py:323] From C:\\Users\\Gencho\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 200)         1200000   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 64)          59648     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,260,969\n",
      "Trainable params: 1,260,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "detector = PropagandaDetector(textPreprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "non-propaganda    31965\n",
       "propaganda         4021\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_train, dataframe_val = train_test_split(dataframe, test_size = 0.25, stratify=dataframe[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = textPreprocessor.prepare_for_model(dataframe_train['article_prepared'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = dataframe_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1003 13:06:56.703081 20160 deprecation_wrapper.py:119] From C:\\Users\\Gencho\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "26989/26989 [==============================] - 122s 5ms/step - loss: 0.2998 - accuracy: 0.9013\n",
      "Epoch 2/2\n",
      "26989/26989 [==============================] - 107s 4ms/step - loss: 0.1048 - accuracy: 0.9624\n"
     ]
    }
   ],
   "source": [
    "detector.train(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.save_model(\"./model/detector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_val = textPreprocessor.prepare_for_model(dataframe_val['article_prepared'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_val = dataframe_val['target'].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = detector.model.predict(features_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 0.7800687285223368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7932,  324],\n",
       "       [  60,  681]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('F1-score: {0}'.format(f1_score(predictions, labels_val)))\n",
    "confusion_matrix(predictions, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = PropagandaDetector(textPreprocessor, \"./model/detector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 1s 822ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False, 0.0022902624)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.detect_propaganda(dataframe['article'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO: Clean up all that above aswell..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
